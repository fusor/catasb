---
ssh_key_name: ""
target_dns_zone: ""
target_subdomain: ""
instance_name: ""
instance_lookup_value: ""
ec2_install: true

#aws_tag_prefix is used to name the various VPC resources so they are only created once per account
#even if shared with multiple IAM users
aws_tag_prefix: "test_awsdemo"

##
# us-east-1
##
aws_region: us-east-1
aws_ami_id: ami-b63769a1

##
# us-east-2
##
#aws_region: us-east-2
#aws_ami_id: ami-0932686c

##
# us-west-1
##
#aws_region: us-west-1
#aws_ami_id:  ami-2cade64c

##
# us-west-2
##
#aws_region: us-west-2
#aws_ami_id: ami-6f68cf0f

##
# Canada
##
#aws_region: ca-central-1
#aws_ami_id: ami-9062d0f4

instance_type: c4.4xlarge

# For local setup, especially on Mac the hostname will be
# different from the routing_suffix. We expect the hostname for
# Mac to be the public IP. This is needed so oc cluster up and
# can ensure it's listening on the correct interface.
#
# For ec2 runs this is less important to differentiate and we expect
# hostname and openshift_routing_suffix to be the same
#
hostname: "{{target_subdomain}}.{{target_dns_zone}}"
openshift_routing_suffix: "{{target_subdomain}}.{{target_dns_zone}}"
cluster_url: "{{ hostname }}:8443"

use_ssl: True
email_address: "foo@bar.com"

var_lib_docker_ebs_device_name: "sdc"
var_lib_docker_block_device: "/dev/xvdc"
var_lib_docker_mount_point: "/var/lib/docker"

docker_vg_ebs_device_name: "sdd"
docker_vg_block_device: "/dev/xvdd"
docker_vg_name: "docker_vg"

persistedvol_ebs_device_name: "sde"
persistedvol_block_device: "/dev/xvde"
persistedvol_mount_point: "/persistedvolumes"

tmp_ebs_device_name: "sdf"
tmp_block_device: "/dev/xvdf"
tmp_mount_point: "/tmp"


cluster_master_config_file: /var/lib/origin/openshift.local.config/master/master-config.yaml
cluster_auth_htpasswd_file: /var/lib/origin/openshift.local.config/master/catasb_auth_htpasswd
cluster_user: admin
cluster_user_password: admin
cluster_system_admin: "system:admin"
scc_anyuid: False

oc_client_install_path: "/usr/local/bin"
oc_cmd: "{{ oc_client_install_path }}/oc"
oadm_cmd: "{{ oc_client_install_path }}/oadm"
kubectl_cmd: "{{ oc_client_install_path }}/kubectl"

origin_image_name: docker.io/openshift/origin
origin_image_tag: v3.6.0
oc_host_config_dir: /var/lib/origin/openshift.local.config

asb_project: ansible-service-broker


# If you want to make changes to deploying the broker, grab a copy of the template and make local changes and update it to point to 'asb_template_url'
# remember to use a file:// path as in:
# asb_template_url: file:///path/to/file/deploy.yaml.j2
asb_template_url: https://raw.githubusercontent.com/openshift/ansible-service-broker/master/templates/deploy-ansible-service-broker.template.yaml
k8s_asb_template_url: https://raw.githubusercontent.com/openshift/ansible-service-broker/master/templates/k8s-ansible-service-broker.yaml.j2

broker_registry_type: dockerhub
broker_registry_url: docker.io
# Need to shortern registry_name for short term due to below issue where podpreset
# name needs to be under 63 chars
#https://github.com/openshift/ansible-service-broker/issues/283
broker_registry_name: dh
broker_dev_broker: false
broker_launch_apb_on_bind: false
broker_output_request: false
broker_recovery: true
broker_enable_basic_auth: false
broker_bootstrap_refresh_interval: 600s
broker_sandbox_role: edit
broker_pull_policy: "IfNotPresent"
broker_auto_escalate: true

broker_image_name: docker.io/ansibleplaybookbundle/origin-ansible-service-broker
broker_tag: "latest"
broker_image: "{{ broker_image_name }}:{{ broker_tag }}"


etcd_tag: "latest"
etcd_image_name: "quay.io/coreos/etcd"
etcd_image: "{{ etcd_image_name }}:{{ etcd_tag }}"
etcd_path: "/usr/local/bin/etcd"

local_oc_client: false

# Location where we will store the local template, note this will always attempt to fetch and overwrite from 'asb_template_url'
# If you want to modify the template, modify 'asb_template_url'
local_target_asb_template: /tmp/deploy-ansible-service-broker.template.yaml.local
local_target_asb_template_processed: /tmp/deploy-ansible-service-broker.template.yaml.local.processed

deploy_rds_demo_instance: true

aws_sec_group_name: "{{ aws_tag_prefix }}_security_group"
vpc_name: "{{ aws_tag_prefix }}_vpc"
vpc_cidr_block: "10.0.0.0/16"
vpc_subnet_a_cidr: "10.0.0.0/24"
vpc_subnet_a_name: "{{ aws_tag_prefix }}_subnet_a"
vpc_subnet_b_cidr: "10.0.1.0/24"
vpc_subnet_b_name: "{{ aws_tag_prefix }}_subnet_b"
vpc_route_table_name: "{{ aws_tag_prefix }}_route_table"
rds_subnet_group_name: "{{ aws_tag_prefix }}_rds_group"

# If true, will remove all docker images from 'docker_images_group1'
remove_docker_images: false

rcm: false
# asb_scheme specifies if the route for the broker is using http or https
# for older builds such as release-0.9 only http is supported
# newer builds default to https
asb_scheme: https

# These docker images we want to remove and fetch on each setup
docker_images_group1:
  - { img: "{{ broker_image_name }}", tag: "{{ broker_tag }}" }
  - { img: "{{ origin_image_name }}-service-catalog", tag: "{{ origin_image_tag }}" }

# These docker images change less frequently, we are OK pulling them once and reusing
docker_images_group2:
  - { img: "{{ etcd_image_name }}", tag: "{{ etcd_tag }}" }
  - { img: "{{ origin_image_name }}", tag: "{{ origin_image_tag }}" }
  - { img: "{{ origin_image_name }}-sti-builder", tag: "{{ origin_image_tag }}" }
  - { img: "{{ origin_image_name }}-deployer", tag: "{{ origin_image_tag }}" }
  - { img: "{{ origin_image_name }}-docker-registry", tag: "{{ origin_image_tag }}" }
  - { img: "{{ origin_image_name }}-pod", tag: "{{ origin_image_tag }}" }
  - { img: "{{ origin_image_name }}-haproxy-router", tag: "{{ origin_image_tag }}" }

coalmine_apiserver: quay.io/kubernetes-service-catalog/apiserver:canary
coalmine_controller: quay.io/kubernetes-service-catalog/controller-manager:canary

